# Identifying-Fake-Job-Postings
Web Based Application which helps Classify a given Job Posting to be Real Or Fake

Problem Statement: 

  ->The rapid growth of online job postings has increased fraudulent job advertisements, causing job seekers to lose time, data, and trust. A robust solution is needed to identify fake job postings and ensure the reliability of online recruitment systems.

Purpose: 
  
  ->This project aims to develop an automated system to predict fraudulent job posts, enhancing the safety and efficiency of online job applications and combating scams in the recruitment industry.

Solution: 
  
  ->Using the Employment Scam Aegean Dataset (EMSCAD) containing 18,000 samples, we applied both traditional machine learning and deep learning techniques to classify job postings as legitimate or fraudulent. Contributed in developing a web based application which helps it's registered users with a easy to use job post verification service, where the user can copy paste any existing online job post's description on the "Custom Job Verification" web page, which will produce a result stating whether the job post is Legitimate or Fraudulent. Which would help prevent the job seeker from falling into the trap of fradulent jobs.   
![image](https://github.com/user-attachments/assets/928455cc-99ab-432c-acdf-19deffe8bc8b)



Approach Taken:
  1. Data Preprocessing:
    Normalization and cleaning of data to prepare it for analysis and training.
    Ensured minimal redundancy in data structure using DBMS normalization techniques.
  2. Algorithms Used:
    Traditional Machine Learning: KNN, SVM, Decision Tree, Naive Bayes, Random Forest, and Multilayer Perceptron (MLP).
    Deep Learning: Deep Neural Network (DNN) with three dense layers for robust classification.
  3. Frontend Development:
    Designed an intuitive and interactive interface using HTML and CSS, featuring animations and a floating navigation bar for seamless user experience.
  4. Database Management:
    Implemented and optimized the backend database for faster data retrieval and updates, reducing redundancy and ensuring smooth operations.

Results:
  
  ->Among traditional machine learning models, Random Forest delivered the highest accuracy.

Problems Yet to Tackle:
  1. Identifying adversarial attacks that can bypass classification models.
  2. Scalability for larger datasets and real-time analysis.

Issues Yet to Solve
  1. Real-time detection in dynamic environments.
  2. Enhanced feature extraction for improving classification robustness.

Possible Improvements
  1. Implementing ensemble methods combining deep learning and traditional models for greater accuracy.
  2. Real-time fraud detection API for live job portals.
  3. Expanding the dataset for increased generalizability.

My Role
  1. Frontend Development:

     ->Contributed to the web application's user interface by creating visually appealing, easy-to-navigate pages. Added animations and responsive design elements, ensuring a fast request-response loop between frontend and backend.
     
  3. Database Management:

     ->Assisted in database architecture and normalization to reduce redundancy. Ensured efficient data storage and retrieval, facilitating seamless integration between the database and the web application.
